import gradio as gr
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import json
import os
import random
import matplotlib.pyplot as plt

INTEGRITY_MODEL_PATH = "models/integrity_model.pth"
CLEANLINESS_MODEL_PATH = "models/cleanliness_model.pth"
TIRES_MODEL_PATH = "models/tires_model.pth"
GLASS_MODEL_PATH = "models/glass_model.pth"
VIEWPOINT_MODEL_PATH = "models/viewpoint_model.pth"

INTEGRITY_CLASSES = ['damaged', 'intact']
CLEANLINESS_CLASSES = ['clean', 'dirty']
TIRES_CLASSES = ['flat', 'ok']
GLASS_CLASSES = ['cracked', 'ok']
VIEWPOINT_CLASSES = ['front', 'rear', 'side']

DEVICE = torch.device("cpu")


# --- 2. –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô ---
def load_model(model_path, num_classes):
    model = models.resnet50()
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, num_classes)
    try:
        model.load_state_dict(torch.load(model_path, map_location=DEVICE))
    except FileNotFoundError:
        print(f"!!! –í–ù–ò–ú–ê–ù–ò–ï: –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}. –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –Ω–µ–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å.")
    model.to(DEVICE)
    model.eval()
    return model


print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
models_to_load = {
    "integrity": (INTEGRITY_MODEL_PATH, len(INTEGRITY_CLASSES)),
    "cleanliness": (CLEANLINESS_MODEL_PATH, len(CLEANLINESS_CLASSES)),
    "tires": (TIRES_MODEL_PATH, len(TIRES_CLASSES)),
    "glass": (GLASS_MODEL_PATH, len(GLASS_CLASSES)),
    "viewpoint": (VIEWPOINT_MODEL_PATH, len(VIEWPOINT_CLASSES)),
}
ml_models = {name: load_model(path, num_cls) for name, (path, num_cls) in models_to_load.items()}


preprocess = transforms.Compose([
    transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])


# --- 3. –õ–û–ì–ò–ö–ê –ê–ù–ê–õ–ò–ó–ê –ò –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò ---
def predict_real(model, image, class_names):
    img_t = preprocess(image)
    batch_t = torch.unsqueeze(img_t, 0).to(DEVICE)
    with torch.no_grad():
        out = model(batch_t)
        probs = torch.nn.functional.softmax(out, dim=1)[0]
    pred_class = class_names[torch.argmax(probs)]
    confidence = torch.max(probs).item()
    return pred_class, confidence


def create_score_chart(score, status):
    if score is None: return None

    fig, ax = plt.subplots(figsize=(3, 3), facecolor='#F9FAFB')
    ax.set_aspect('equal')

    color_map = {"–û—Ç–ª–∏—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ": '#2ca02c', "–¢—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è": '#ff7f0e', "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ": '#d62728'}
    color = color_map.get(status, '#2ca02c')

    ax.pie([score, 100 - score], startangle=90, colors=[color, '#e6e6e6'], wedgeprops=dict(width=0.4))
    ax.text(0, 0, f"{score}", ha='center', va='center', fontsize=28, fontweight='bold', color=color)

    plt.tight_layout()
    return fig


def create_status_alert(status):
    color_map = {"–û—Ç–ª–∏—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ": 'green', "–¢—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è": 'orange', "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ": 'red'}
    icon_map = {"–û—Ç–ª–∏—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ": '‚úÖ', "–¢—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è": '‚ö†Ô∏è', "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ": '‚ùóÔ∏è'}

    color = color_map.get(status, 'grey')
    icon = icon_map.get(status, '‚ùì')

    return f"""<div style="padding: 15px; border-radius: 10px; background-color: {color}; color: white; text-align: center; font-family: sans-serif;">
               <h2 style="margin: 0;">{icon} {status}</h2></div>"""


def calculate_overall_score(analysis_results):
    score = 100
    issues, penalties = [], {'integrity': {'damaged': 40}, 'cleanliness': {'dirty': 10}, 'tires': {'flat': 20},
                             'glass': {'cracked': 35}}
    readable_names = {'integrity': '–ü–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –∫—É–∑–æ–≤–∞', 'cleanliness': '–ó–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–µ', 'tires': '–ü—Ä–æ–±–ª–µ–º–∞ —Å —à–∏–Ω–∞–º–∏',
                      'glass': '–¢—Ä–µ—â–∏–Ω—ã –Ω–∞ —Å—Ç–µ–∫–ª–µ'}

    for key, result in analysis_results.items():
        if key in penalties and result['status'] in penalties[key]:
            score -= penalties[key][result['status']]
            issues.append(readable_names[key])

    score = max(0, score)
    if score >= 90:
        status = "–û—Ç–ª–∏—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"
    elif 90 > score >= 60:
        status = "–¢—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è"
    else:
        status = "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"
    return score, status, issues


def generate_recommendation_with_gemma(score, issues):
    """(–°–∏–º—É–ª—è—Ü–∏—è) –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π."""
    # ... (–ª–æ–≥–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
    if not issues: return "–ê–≤—Ç–æ–º–æ–±–∏–ª—å –≤ –æ—Ç–ª–∏—á–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–µ—Ç. –°—á–∞—Å—Ç–ª–∏–≤–æ–≥–æ –ø—É—Ç–∏!"
    prompt_details = f"–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {score}/100. –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã: {', '.join(issues)}."
    print(f"\n--- –ü–†–û–ú–ü–¢ –î–õ–Ø GEMMA ---\n{prompt_details}\n-----------------------\n")
    recommendation = "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ù–∞—à–∞ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≤–µ–ª–∞ –∞–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤–∞—à–µ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è.\n\n"
    if "–ü—Ä–æ–±–ª–µ–º–∞ —Å —à–∏–Ω–∞–º–∏" in issues: recommendation += "‚ùóÔ∏è **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–∞–º–µ—á–∞–Ω–∏–µ:** –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≤–æ–∑–º–æ–∂–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Å —à–∏–Ω–æ–π. **–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–≤–ª–µ–Ω–∏–µ –≤ —à–∏–Ω–∞—Ö –ø–µ—Ä–µ–¥ –ø–æ–µ–∑–¥–∫–æ–π –¥–ª—è –≤–∞—à–µ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.**\n\n"
    if "–¢—Ä–µ—â–∏–Ω—ã –Ω–∞ —Å—Ç–µ–∫–ª–µ" in issues: recommendation += "‚ö†Ô∏è **–í–∞–∂–Ω–æ–µ –∑–∞–º–µ—á–∞–Ω–∏–µ:** –ó–∞–º–µ—á–µ–Ω—ã —Ç—Ä–µ—â–∏–Ω—ã –Ω–∞ —Å—Ç–µ–∫–ª–µ. –≠—Ç–æ –º–æ–∂–µ—Ç —É—Ö—É–¥—à–∏—Ç—å –æ–±–∑–æ—Ä. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ —Å–µ—Ä–≤–∏—Å.\n\n"
    if "–ü–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –∫—É–∑–æ–≤–∞" in issues: recommendation += "‚ÑπÔ∏è **–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:** –ï—Å—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –∫—É–∑–æ–≤–∞. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–º–æ–Ω—Ç.\n\n"
    if "–ó–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–µ" in issues: recommendation += "‚ÑπÔ∏è **–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:** –ê–≤—Ç–æ–º–æ–±–∏–ª—å –≤—ã–≥–ª—è–¥–∏—Ç –≥—Ä—è–∑–Ω—ã–º. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ø–æ—Å–µ—Ç–∏—Ç—å –º–æ–π–∫—É.\n\n"
    return recommendation + "–°–ø–∞—Å–∏–±–æ –∑–∞ –∑–∞–±–æ—Ç—É –æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–µ —Å–µ—Ä–≤–∏—Å–∞!"


def full_analysis(image):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –∑–∞–ø—É—Å–∫–∞—é—â–∞—è –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω –∞–Ω–∞–ª–∏–∑–∞."""
    if image is None: return None, "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", None, {}, "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"

    results = {
        'integrity': predict_real(ml_models['integrity'], image, INTEGRITY_CLASSES),
        'cleanliness': predict_real(ml_models['cleanliness'], image, CLEANLINESS_CLASSES),
        'tires': predict_real(ml_models['tires'], image, TIRES_CLASSES),
        'glass': predict_real(ml_models['glass'], image, GLASS_CLASSES),
        'viewpoint': predict_real(ml_models['viewpoint'], image, VIEWPOINT_CLASSES),
    }

    internal_results = {k: {'status': v[0]} for k, v in results.items()}
    score, status, issues = calculate_overall_score(internal_results)

    chart = create_score_chart(score, status)
    status_alert = create_status_alert(status)
    recommendation = generate_recommendation_with_gemma(score, issues)

    detailed_report = {
        '–¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å': {'—Å—Ç–∞—Ç—É—Å': results['integrity'][0], '—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': f"{results['integrity'][1]:.2f}"},
        '–ß–∏—Å—Ç–æ—Ç–∞': {'—Å—Ç–∞—Ç—É—Å': results['cleanliness'][0], '—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': f"{results['cleanliness'][1]:.2f}"},
        '–®–∏–Ω—ã': {'—Å—Ç–∞—Ç—É—Å': results['tires'][0], '—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': f"{results['tires'][1]:.2f}"},
        '–°—Ç–µ–∫–ª–∞': {'—Å—Ç–∞—Ç—É—Å': results['glass'][0], '—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': f"{results['glass'][1]:.2f}"},
        '–†–∞–∫—É—Ä—Å': {'—Å—Ç–∞—Ç—É—Å': results['viewpoint'][0], '—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': f"{results['viewpoint'][1]:.2f}"}
    }

    return chart, status_alert, recommendation, detailed_report, image


# --- 4. –ò–ù–¢–ï–†–§–ï–ô–° –î–ê–®–ë–û–†–î–ê ---
EXAMPLES_DIR = "examples"
example_images = []
if os.path.exists(EXAMPLES_DIR):
    all_examples = [os.path.join(EXAMPLES_DIR, f) for f in os.listdir(EXAMPLES_DIR) if
                    f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    example_images = random.sample(all_examples, min(5, len(all_examples)))

with gr.Blocks(theme=gr.themes.Soft(primary_hue="blue"), title="–î–∞—à–±–æ—Ä–¥ –ê–Ω–∞–ª–∏–∑–∞ –ê–≤—Ç–æ") as demo:
    gr.Markdown("# üöò –î–∞—à–±–æ—Ä–¥ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è")
    gr.Markdown(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–π –æ—Ü–µ–Ω–∫–∏, –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤–æ–¥–∏—Ç–µ–ª—é.")

    with gr.Row():
        with gr.Column(scale=2):
            input_image = gr.Image(type="pil", label="–§–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è")
            submit_btn = gr.Button("–ü—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑", variant="primary", scale=1)
            gr.Examples(examples=example_images, inputs=input_image, label="–°–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

        with gr.Column(scale=3):
            with gr.Row():
                with gr.Column(scale=1, min_width=200):
                    output_score_chart = gr.Plot(label="–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞")
                with gr.Column(scale=2, min_width=300):
                    output_status = gr.Markdown(label="–°—Ç–∞—Ç—É—Å –∞–≤—Ç–æ–º–æ–±–∏–ª—è")

            output_recommendation = gr.Markdown(label="–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è")
            output_details = gr.JSON(label="–ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –º–æ–¥–µ–ª–µ–π")

    submit_btn.click(
        fn=full_analysis,
        inputs=input_image,
        outputs=[output_score_chart, output_status, output_recommendation, output_details, input_image]
    )

if __name__ == "__main__":
    demo.launch(debug=True)

